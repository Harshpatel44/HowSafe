# News
<h2>Data cleaning</h2>
1. Remove all unwanted characters<br>
2. Remove duplicates in the tokens<br>
3. Lematize the words before finding frequency of them<br>
4. Remove numbers and symbols from frequency of words<br>
5. Remove the pos tags (removed tags [VBD, IN, DT] and removed unwanted words from tags [JJ,NN,NNS], kept [JJS] unchanged. )<br>
6. Remove stop words<br>
7. Find frequency of words<br>
8. count 2-gram and 3-gram frequency of words<br>
9. Remove all the 2 letter words<br>
<br>
<h2>Notes:</h2><br>
First I planned to remove the some POS_TAG words from the list, but<br>
I need to remove all the unwanted words of all the tenses using lematizing<br>
bi-gram and tri-grams need to be created.<br>
